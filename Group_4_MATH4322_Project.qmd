---
title: "Concrete Compressive Strength."
subtitle: "Group 4 Team Project."
author: "Alejandro Avila, Anthony Ramirez, Benjamin B An, Chengze Liu, Vishu Kodikanti."
format: pdf
highlight-style: github
editor: visual
code-block-bg: true
code-block-border-left: "#31BAE9"
title-block-style: plain
header-includes: 
- \newcommand{\bi}{\begin{itemize}}
- \newcommand{\ei}{\end{itemize}}
- \newcommand{\iset}{\setlength\itemsep{1em}}
- \usepackage{amsbsy}
- \usepackage{hyperref}

---



```{r echo=FALSE, out.width = '100%'}
knitr::include_graphics("concrete.jpg")
```

\newpage

\raggedright

## Introduction

Concrete is the most important material in civil engineering, and concrete compressive strength is one determining factor for concrete performance. The chemical compositions, physical formations, as well as the age of concrete, may impact its compressive strength. With gratitude to I-Cheng Yeh from UC Irvine Machine Learning Repository, we examine the dataset **Concrete Compressive Strength**. We create two different models using the concrete compressive strength dataset: one utilizing linear regression and the other employing a random forest approach. Our goal is to determine the best model and identify the most significant predictors to aid in predicting concrete compressive strength.

## Dataset Description

The dataset provided by the UC Irvine Machine Learning Repository will help us investigate the influence of different materials on concrete compression strength. This dataset consists of 1030 observations and 9 variables. Among these, 8 variables serve as predictors, while 1 variable serves as the response variable. Together, they offer a robust and comprehensive dataset that forms the foundation for our analysis. Each piece of data in this dataset tells us about a specific mix of materials, how they are assembled, and the conditions they are subjected to. The dataset helps to identify all the factors contributing to the strength of concrete. In the following sections, we will provide detailed information about these variables:

## Predictors:
\begin{itemize}
    \item \textbf{\textit{Cement}}: is a continuous numerical value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and is the binder that sets,hardens and adheres to other materials to bind them together.
    \item \textbf{\textit{Blast\_Furnace\_Slag}}: is an integer numerical value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and is a byproduct of iron when added to concrete improves its properties suck as workability, strength and durability.
    \item \textbf{\textit{Fly\_Ash}}: is a continuous numerical value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and is a byproduct of coal power plants that can be used to improve durability and workability of concrete mixes.
    \item \textbf{\textit{Water}}: is a numerical continuous value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and water is added to concrete that helps to create a paste that glues all aggregates together.
    \item \textbf{\textit{Superplasticizer}}: is a numerical continuous value measured in kilograms per cubic meter and is an admixture that transforms stiff, low-slump concrete into flowing, pourable and easily placed concrete.
    \item \textbf{\textit{Coarse\_Aggregate}}: is a numerical continuous value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and is typically made up of crushed stone, gravel, or recycled concrete. It is used to provide bulk to the concrete mixture, which helps to reduce shrinkage and cracking.
    \item \textbf{\textit{Fine\_Aggregate}}: is a numerical continuous value measured in kilograms per cubic meter (kg/m\textsuperscript{3}) and is a term used to describe small, inert materials, whether granular or crushed stone. These fine aggregates are essential components in concrete mixtures and play a crucial role in determining the properties of the resulting concrete.
    \item \textbf{\textit{Age}}: is an integer numerical value measured in days and this variable refers to the number of days since the concrete sample was created or cast.
\end{itemize}


## Response:

\begin{itemize}
\item \textbf{\textit{Concrete\_Strength}}: The target variable in our data set is a continuous numerical value expressed in megapascals (MPa). It represents the compressive strength of materials, in this case concrete, and is widely utilized in material science and engineering for assessing the strength characteristics of substances.
\end{itemize}

## Importing the data set.

We read our CSV file and print the dataset summary with the following code: 

```{r}
#importing the data set and displaying the summary
strength<-read.csv("C:/Users/alex-/OneDrive/Desktop/Concrete.csv")
summary(strength)

```
The summary shows all the predictors in our dataset: \textcolor{black}{\textit{Cement}}, \textcolor{black}{\textit{Blast\_furnace\_slag}}, \textcolor{black}{\textit{Fly\_Ash}}, \textcolor{black}{\textit{Water}}, \textcolor{black}{\textit{Superplasticizer}}, \textcolor{black}{\textit{Coarse\_Aggregate}}, \textcolor{black}{\textit{Fine\_Aggregate}}, \textcolor{black}{\textit{Age}} and the target variable \textcolor{black}{\textit{Concrete\_Strength}}. We can interpret the data as follows: 

\begin{itemize}
    \item \textbf{\textit{Cement}}: The minimum amount of cement used is 102.0 (kg/m\textsuperscript{3}), and the maximum is 540.0 (kg/m\textsuperscript{3}). The mean of cement used is approximately 281.2 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Blast\_Furnace\_Slag}}: The minimum amount of Blast Furnace Slag used is 0.0 (kg/m\textsuperscript{3}), and the maximum is 359.4 (kg/m\textsuperscript{3}). The mean of Blast Furnace Slag used is approximately 73.9 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Fly\_Ash}}: The minimum amount of Fly Ash used is 0.0 (kg/m\textsuperscript{3}), and the maximum is 200.1 (kg/m\textsuperscript{3}). The mean of Fly Ash used is approximately 54.19 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Water}}: The minimum amount of water used is 121.8 (kg/m\textsuperscript{3}), and the maximum is 247.0 (kg/m\textsuperscript{3}). The mean of water used is approximately 181.6 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Superplasticizer}}: The minimum amount of Superplasticizer used is 0.0 (kg/m\textsuperscript{3}), and the maximum is 32.2 (kg/m\textsuperscript{3}). The mean of Superplasticizer used is approximately 6.205 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Coarse\_Aggregate}}: The minimum amount of Coarse Aggregate used is 801.0 (kg/m\textsuperscript{3}), and the maximum is 1145.0 (kg/m\textsuperscript{3}). The mean of Coarse Aggregate used is approximately 972.9 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Fine\_Aggregate}}: The minimum amount of Fine Aggregate used is 594.0 (kg/m\textsuperscript{3}), and the maximum is 992.6 (kg/m\textsuperscript{3}). The mean of Fine Aggregate used is approximately 773.6 (kg/m\textsuperscript{3}).
    \item \textbf{\textit{Age}}: The minimum amount of days in Age is one day, and the maximum is 365 days. The mean of Age is approximately 45.66 days.
    \item \textbf{\textit{Concrete\_Strength}}: The minimum amount of the concrete compressive strength is 2.33 MPa, and the maximum is 82.60 MPa. The mean of the concrete compressive strength is 35.82.
\end{itemize}



Then we check if we have any missing values in our dataset: 

```{r}
any(is.na(strength))
```
We get FALSE as a result showing that our dataset does not have any missing values.

## Linear Regression

Linear regression is a statistical technique used to understand and quantify the relationship between one or more predictor variables and a continuous outcome variable. In our analysis, we employ linear regression to investigate how changes in certain characteristics of concrete mixtures relate to the compressive strength of the resulting concrete.

The fundamental concept behind linear regression is to find the best-fitting line that represents the relationship between the predictor variables and the outcome variable. This line is characterized by an intercept term ($\beta_0$) and slope coefficients ($\beta_1$,$\beta_2$,..,$\beta_n$) associated with each predictor variable.

The equation of the linear regression model can be expressed as:

p(x)=$\beta_0$ + $\beta_1$ $\times$ $x_1$ + $\beta_2$ $\times$ $x_2$ + ... + $\beta_n$ $\times$ $x_n$

In this equation, p(x)  represents the predicted outcome variable, while $x_1$,$x_2$,...,$x_n$  represent the predictor variables. The coefficients $\beta_0$,$\beta_1$,...,$\beta_n$ are estimated from the data to minimize the difference between the observed and predicted values of the outcome variable.

When we translate this general formula into our model we get the following linear regression model that we can use to predict our outcome: 

Strength = $\beta_0$ +$\beta_1$ $\times$ Cement + $\beta_2$ $\times$ Blast Furnace Slag + $\beta_3$ $\times$ Fly Ash+ $\beta_4$ $\times$ Water
+$\beta_5$ $\times$ Superplasticizer+ $\beta_6$ $\times$ Coarse Aggregate+$\beta_7$ $\times$ Fine Aggregate+ $\beta_8$ $\times$ Age +$\epsilon$

Then we use the following code to create our linear model and to print a summary of our model:

#Creating the linear regression model and printing summary 
```{r}
strength.lm = lm(Concrete_Strength ~ .,data=strength)
summary(strength.lm)

```
From the above summary of our linear regression we can observe that the predictors: Cement, Blast_furnace_slag, Fly_Ash, Water, Superplasticizer and Age are statistically significant in predicting the concrete compressive strength because the p-value is less than the significance level of 0.05, indicating strong evidence against the null hypothesis that the coefficient for these predictors is zero. This means that changes in the amounts of these materials, along with the age of the concrete, have a significant impact on its compressive strength. 

Additionally, the coefficients for these predictors are positive, suggesting that increases in their amounts lead to higher concrete compressive strength Conversely, the coefficient for Water is negative, indicating that higher water content in the concrete mixture is associated with lower compressive strength. The model's overall performance is reasonably good, with an adjusted R-squared value of 0.6125, indicating that approximately 61.25% of the variability in concrete compressive strength is explained by the predictors included in the model.

While these p-values are slightly above 0.05 for Coarse_Aggregate (0.0544525) and Fine_Aggregate (0.059491), they are still relatively low, indicating that there is some evidence to reject the null hypothesis that the coefficients for these variables are zero.In practical terms, this suggests that there may still be a meaningful relationship between Coarse_Aggregate, Fine_Aggregate, and concrete compressive strength, but their significance is weaker compared to other predictors in the model.Therefore, while Coarse_Aggregate and Fine_Aggregate may not be as strongly associated with concrete compressive strength as other variables in the model, We think they need to be still considered becaue they are relatively close to the significant p-value of 0.05.

## Linear regression plots

We will now create plots for the linear model we have constructed. We will use the following code to generate the Residuals vs Fitted Plot, the Q-Q Residuals Plot, the Scale-Location Plot, and the Residuals vs Leverage Plot. These visual representations will help us better understand our data:

```{r}
par(mfrow = c(2, 2))
plot(strength.lm)
```

From the Residuals vs Fitted plot, we can visually inspect the relationship between the predicted values and the residuals. This helps in identifying patterns or trends in the residuals, which can indicate potential issues with the model assumptions or data. In our plot, we observe randomness where our points are scattered around zero. This indicates that the model captures all the information in the data, and there are no systematic errors. We don't observe signs of heteroscedasticity, as the fitted values are not correlated with the residuals; they appear to be independent. The plot exhibits a somewhat linear pattern, and the residuals may occasionally become negative as fitted values increase.

From the Q-Q plot, we can determine if the residuals of the regression model are normally distributed. If the points in this plot fall roughly along a straight diagonal line, then we can assume the residuals are normally distributed. In our plot, we observe that the points fall approximately along a straight line, indicating that the data follows the theoretical distribution closely. This suggests a good fit between the data and the chosen distribution, supporting the assumption of normality for the residuals. Additionally, the straight line alignment indicates that the variability of the residuals is consistent across different quantiles, further validating the model's assumptions.

From the Scale-Location plot, we can determine whether the residuals of a regression model exhibit constant variance across the range of fitted values. In out plot we observe the residuals are approximately constant across the range of fitted values this indicates that the assumption of constant variance (homoscedasticity) is met, and the model's residuals have consistent variability across different levels of the predictor variables.

From the Residual vs Leverage plot, we can determine influential observations; if any points in this plot fall outside of Cook’s distance (the dashed lines), then it is considered an influential observation. In our plot, there are no values outside of the dashed lines. This means there aren’t any overly influential points in our dataset.

## Training testing
In this section, we will train the linear regression model to evaluate its accuracy. We will begin by creating a randomized 80:20 split (training:testing) in our dataset, then scale the numeric variables, calculate the mean squared error (MSE), and perform 10-fold cross-validation. Finally, we will determine the average MSE based on these 10 iterations.
```{r}
MSE <- rep(0, 10)

for (i in 1:10) {
  set.seed(i)
  sample <- sample(1:nrow(strength), 0.8 * nrow(strength))
  train_data <- strength[sample, ]  
  test_data <- strength[-sample, ]  
  
  numeric_cols <- sapply(train_data, is.numeric)
  train_data_scaled <- as.data.frame(scale(train_data[, numeric_cols]))
  test_data_scaled <- as.data.frame(scale(test_data[, numeric_cols]))
  
  # Fit linear regression model
  strength.lm <- lm(Concrete_Strength ~ ., data = train_data_scaled)
  
  # Make predictions
  yhat <- predict(strength.lm, newdata = test_data_scaled)
  
  # Calculate MSE
  MSE[i] <- mean((yhat - test_data_scaled$Concrete_Strength)^2)
}

cat("MSE Values:", MSE, "\n")
cat("Average Test MSE:", mean(MSE), "\n")



```
The average test Mean Squared Error (MSE) obtained across all 10 training and testing iterations is 0.3762034. This indicates that, on average, the squared difference between the predicted concrete strength values and the actual values in the test set is 0.376. The Mean Squared Error (MSE) serves as a quantitative measure of how well the model's predictions align with the true values. 

By averaging the squared differences between each predicted value and its corresponding actual value, the MSE offers insight into the predictive accuracy of the model. A lower MSE suggests that the model's predictions are closer to the true values, indicating higher predictive accuracy and better performance overall. Given the relatively low MSE value obtained in this analysis, it suggests that the model performs well in predicting concrete strength, making it a good model for this particular dataset.

# Random Forest

We separate the data set to training and test (70/30).

```{r}
library(randomForest)
set.seed(200)
rf_train_subset = sample(1:nrow(strength), nrow(strength)*0.7)
test.sample = strength[-rf_train_subset,]
rf.strength = randomForest(Concrete_Strength ~ . , data = strength, subset = rf_train_subset, mtry = ncol((strength)-1)/3, importance = TRUE)
varImpPlot(rf.strength)
yhat_test = predict(rf.strength, newdata = test.sample)
(rf.MSE = mean(test.sample$Concrete_Strength - yhat_test)^2)

MSE_vector = rep(0,10)
for (i in 1:10) {
  set.seed(i) 
  sample <- sample(1:nrow(strength), 0.7 * nrow(strength))
  train_data <- strength[sample, ]
  test_data <- strength[-sample, ]
  
  #scaling numeric variables to have zero mean and unit variance (min-max scaling)
  numeric_cols <- sapply(train_data, is.numeric)
  train_data_scaled <- as.data.frame(scale(train_data[, numeric_cols]))
  test_data_scaled <- as.data.frame(scale(test_data[, numeric_cols]))
  
  concrete.rf = randomForest(Concrete_Strength ~., 
                            data = train_data_scaled,
                            mtry = (ncol(strength)-1) / 3, importance = TRUE)
  
  yhat.rf = predict(concrete.rf, newdata = test_data_scaled)
  MSE_vector[i] = mean((yhat.rf - test_data_scaled$Concrete_Strength)^2)
}

cat("MSE Values:", MSE_vector, "\n")
cat("Average Test MSE:", mean(MSE_vector), "\n")

```
